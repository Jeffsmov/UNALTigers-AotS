import os
import geopandas as gpd
import pandas as pd
import numpy as np
from rasterstats import zonal_stats
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

def load_wpp_props(xlsx_path, year=2020, iso3="HTI"):
    df = pd.read_excel(xlsx_path, sheet_name="Estimates", header=0)
    df2020 = df[(df["Year"] == year) & (df["ISO3 Alpha-code"] == iso3)]
    if df2020.empty:
        raise ValueError(f"No se encontró datos para {iso3} en {year}")
    row = df2020.iloc[0]
    age_cols = [c for c in df.columns if isinstance(c, str) and " a " in c]
    total = row[age_cols].sum()
    return {
        "p_u5":  row["0 a 4"]      / total,
        "p_u10": (row["0 a 4"] + row["5 a 9"])                   / total,
        "p_u15": (row["0 a 4"] + row["5 a 9"] + row["10 a 14"])  / total
    }

def sample_pop(grid_gdf, raster_path, field):
    stats = zonal_stats(vectors=grid_gdf.geometry,
                        raster=raster_path,
                        stats=["sum"],
                        nodata=None,
                        all_touched=True)
    grid_gdf[field] = [s["sum"] or 0 for s in stats]

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

def create_session(retries=3, backoff_factor=1, timeout=30):
    session = requests.Session()
    retry = Retry(
        total=retries,
        backoff_factor=backoff_factor,
        status_forcelist=[500, 502, 503, 504],
        allowed_methods=["GET"],
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.mount("https://", adapter)
    # inyectamos timeout por defecto
    original_request = session.request
    def request_with_timeout(method, url, **kwargs):
        kwargs.setdefault("timeout", timeout)
        return original_request(method, url, **kwargs)
    session.request = request_with_timeout
    return session

session = create_session()

def fetch_wb_indicator_latest(iso: str, indicator: str):
    """
    Devuelve (valor, año) siendo el valor más reciente no nulo
    de la serie `indicator` para el país `iso`.
    """
    url = (
        f"https://api.worldbank.org/v2/country/{iso}/indicator/{indicator}"
        f"?mrv=1&format=json&per_page=1"
    )
    try:
        resp = session.get(url)
        resp.raise_for_status()
        data = resp.json()
    except Exception as e:
        print(f"⚠️ Error al consultar {indicator}: {e}")
        return None, None

    # data[1] contiene la lista de observaciones; mrv=1 → a lo sumo 1 elemento
    if len(data) < 2 or not data[1]:
        print(f"⚠️ No hay observaciones para {iso}/{indicator}")
        return None, None

    rec = data[1][0]
    return rec.get("value"), int(rec.get("date", 0))

def main():
    # Rutas de archivos
    TIFF       = "./data/raw/worldpop/ppp_2020_1km_Aggregated.tif"
    XLSX       = "./data/raw/worldpop/WPP2024_POP_F02_1_POPULATION_5-YEAR_AGE_GROUPS_BOTH_SEXES.xlsx"
    H3GEO      = "./data/processed/h3_grid_haiti_res7.geojson"
    OUTPUT_GEO = "./data/processed/h3_vulnerability_child.geojson"

    # 1–4: igual que antes…
    props = load_wpp_props(XLSX)
    h3 = gpd.read_file(H3GEO)
    if "pop_total" not in h3.columns:
        sample_pop(h3, TIFF, "pop_total")
    h3["pop_u5"]  = h3["pop_total"] * props["p_u5"]
    h3["pop_u10"] = h3["pop_total"] * props["p_u10"]
    h3["pop_u15"] = h3["pop_total"] * props["p_u15"]

    # 5. Indicadores base
    maln, _ = fetch_wb_indicator_latest("HTI", "SH.STA.STNT.ZS")
    vacc, _ = fetch_wb_indicator_latest("HTI", "SH.IMM.IDPT")
    maln = maln or 0
    vacc = vacc or 0

    # 5b. Ruido realista: mezcla de distribución
    np.random.seed(42)
    n = len(h3)

    # Parámetros de ruido
    p_outlier    = 0.05            # 5% de celdas serán “outliers”
    sigma_small  = 0.05            # 5% de desviación para ruido normal
    sigma_large  = 0.4             # 40% de desviación para outliers

    # Máscara de outliers
    mask_out = np.random.rand(n) < p_outlier

    # Ruido para malnutrition_prev
    noise_maln = np.where(
        mask_out,
        np.random.normal(0, maln * sigma_large, size=n),
        np.random.normal(0, maln * sigma_small, size=n),
    )
    # Ruido para vaccination_cov
    noise_vacc = np.where(
        mask_out,
        np.random.normal(0, vacc * sigma_large, size=n),
        np.random.normal(0, vacc * sigma_small, size=n),
    )

    # Aplicar ruido y mantener [0,100]
    h3["malnutrition_prev"] = np.clip(maln + noise_maln, 0, 100)
    h3["vaccination_cov"]   = np.clip(vacc + noise_vacc, 0, 100)

    # 6. Guardar GeoJSON final
    os.makedirs(os.path.dirname(OUTPUT_GEO), exist_ok=True)
    h3.to_file(OUTPUT_GEO, driver="GeoJSON")
    print("¡Proceso completado! h3_vulnerability_child.geojson generado.")

if __name__ == "__main__":
    main()